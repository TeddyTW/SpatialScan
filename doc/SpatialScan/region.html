<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.4" />
<title>SpatialScan.region API documentation</title>
<meta name="description" content="Module to contain all region and grid-based construction code." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>SpatialScan.region</code></h1>
</header>
<section id="section-intro">
<p>Module to contain all region and grid-based construction code.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Module to contain all region and grid-based construction code.&#34;&#34;&#34;

from datetime import datetime
from typing import Type
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sbn


class Region:
    &#34;&#34;&#34;Class to represent space-time region&#34;&#34;&#34;

    def __init__(
        self,
        x_min: float,
        x_max: float,
        y_min: float,
        y_max: float,
        t_min: datetime,
        t_max: datetime,
    ) -&gt; None:
        self.x_min = x_min
        self.x_max = x_max
        self.y_min = y_min
        self.y_max = y_max
        self.t_min = t_min
        self.t_max = t_max
        self.label = None

    def __str__(self):
        return &#34;({}, {}) x ({}, {}) x ({}, {})&#34;.format(
            self.x_min, self.x_max, self.y_min, self.y_max, self.t_min, self.t_max
        )

    def add_label(self, label):
        self.label = label

    def num_days(self):
        return (self.t_max - self.t_min).days

    def num_hours(self):
        return (self.t_max - self.t_min).days * 24


def convert_dates(
    df: pd.DataFrame,
    date_start_label=&#34;measurement_start_utc&#34;,
    date_end_label=&#34;measurement_end_utc&#34;,
) -&gt; pd.DataFrame:

    &#34;&#34;&#34; Utility functionality to convert dates in a dataframe from string to
    datetime. Useful when reading in df from csv.
    Args:
        df: Any datafram with date columns
        date_start_label: Label of the column in df corresponding to the start
                          date period.
        date_end_label: Label of the column in df corresponding to the end
                          date period.
    Returns:
        Dataframe with converted date columns
    &#34;&#34;&#34;

    # Check columns are in here.
    assert set([date_start_label, date_end_label]) &lt;= set(df.columns)

    copy_df = df
    copy_df[date_start_label] = pd.to_datetime(df[date_start_label])
    copy_df[date_end_label] = pd.to_datetime(df[date_end_label])
    return copy_df


def aggregate_event_data(
    forecast_data: pd.DataFrame,
    x_ticks: np.ndarray,
    y_ticks: np.ndarray,
    t_ticks: np.ndarray,
) -&gt; pd.DataFrame:
    &#34;&#34;&#34;Functionality to aggregate data in forecast_data (each row represents
    an event) to a data frame consisting N^2 * W rows (each row containing the
    aggregated count in the grid cell it represents).
    Clearly needs to be called after the grid is made.
    Args:
        forecast_data: Data from `count_baseline()`
        x_ticks: x axis grid
        y_ticks: y axis grid
        t_ticks: t_axis grid
    Returns:
        Aggregated Dataframe on Grid Cell Level.
    &#34;&#34;&#34;

    agg_dict = {}
    num_cells = 0
    for i in range(len(x_ticks) - 1):
        for j in range(len(y_ticks) - 1):
            for s in range(len(t_ticks) - 1):
                x_min = x_ticks[i]
                x_max = x_ticks[i + 1]
                y_min = y_ticks[j]
                y_max = y_ticks[j + 1]
                t_min = t_ticks[s]
                t_max = t_ticks[s + 1]

                sub_df = forecast_data[
                    (forecast_data[&#34;lon&#34;].between(x_min, x_max))
                    &amp; (forecast_data[&#34;lat&#34;].between(y_min, y_max))
                    &amp; (forecast_data[&#34;measurement_start_utc&#34;] == t_min)
                    &amp; (forecast_data[&#34;measurement_end_utc&#34;] == t_max)
                ]

                b_count = sub_df[&#34;baseline&#34;].sum()
                b_upper_count = sub_df[&#34;baseline_upper&#34;].sum()
                b_lower_count = sub_df[&#34;baseline_lower&#34;].sum()
                c_count = sub_df[&#34;count&#34;].sum()

                agg_dict[num_cells] = {
                    &#34;x_min&#34;: x_min,
                    &#34;x_max&#34;: x_max,
                    &#34;y_min&#34;: y_min,
                    &#34;y_max&#34;: y_max,
                    &#34;t_min&#34;: t_min,
                    &#34;t_max&#34;: t_max,
                    &#34;baseline_agg&#34;: b_count,
                    &#34;baseline_upper_agg&#34;: b_upper_count,
                    &#34;baseline_lower_agg&#34;: b_lower_count,
                    &#34;count_agg&#34;: c_count,
                }
                num_cells += 1

    return pd.DataFrame.from_dict(agg_dict, &#34;index&#34;)


def event_count(S: Type[Region], agg_data: pd.DataFrame) -&gt; dict:

    &#34;&#34;&#34;Function to calculate both the expected (B) and actual (C) count
    (vehicles) within a given space-time region S from the grid-cell-level-aggregated.
    Used in the likelihood ratio statistic.
    Args:
        S: Space-Time Region to count events in
        agg_data: Event counts aggregated at grid level. eg. from `aggregate_event_data()`
    Returns: (Tuple of floats) both types of event counts within region S.
    &#34;&#34;&#34;

    # Check for columns existence.
    assert set(
        [
            &#34;x_min&#34;,
            &#34;x_max&#34;,
            &#34;y_min&#34;,
            &#34;y_max&#34;,
            &#34;t_min&#34;,
            &#34;t_max&#34;,
            &#34;count_agg&#34;,
            &#34;baseline_agg&#34;,
        ]
    ) &lt;= set(agg_data.columns)

    region_mask = (
        (agg_data[&#34;x_min&#34;] &gt;= S.x_min)
        &amp; (agg_data[&#34;x_max&#34;] &lt;= S.x_max)
        &amp; (agg_data[&#34;y_min&#34;] &gt;= S.y_min)
        &amp; (agg_data[&#34;y_max&#34;] &lt;= S.y_max)
        &amp; (agg_data[&#34;t_min&#34;] &gt;= S.t_min)
        &amp; (agg_data[&#34;t_max&#34;] &lt;= S.t_max)
    )

    S_df = agg_data.loc[region_mask]
    if S_df.empty:
        return {&#39;baseline_agg&#39;: 0, &#39;count_agg&#39;: 0, &#39;baseline_upper_agg&#39;: 0, &#39;baseline_lower_agg&#39;: 0}
    return {&#39;baseline&#39;: S_df[&#39;baseline_agg&#39;].sum() / 1e6,
            &#39;count&#39;: S_df[&#39;count_agg&#39;].sum() / 1e6,
            &#39;baseline_upper&#39;: S_df[&#39;baseline_upper_agg&#39;].sum() / 1e6,
            &#39;baseline_lower&#39;: S_df[&#39;baseline_lower_agg&#39;].sum() / 1e6
    }


def simulate_event_count(S: Type[Region], forecast_data: pd.DataFrame) -&gt; tuple:

    &#34;&#34;&#34;Function to simulate the count (vehicles) within a given
    space-time region S assuming a Poisson Distribution with mean given by the
    baseline forecast. Used in randomisation testing.
    Args:
        S: Space-Time Region to count events in
        data: Forecast data from `count_baseline()`
    Returns: (Tuple of floats) both types of event counts within region S.
    &#34;&#34;&#34;

    # Check for columns existence.
    assert set([&#34;lon&#34;, &#34;lat&#34;, &#34;measurement_end_utc&#34;, &#34;count&#34;, &#34;baseline&#34;]) &lt;= set(
        forecast_data.columns
    )

    forecast_data[&#34;simulated&#34;] = np.random.poisson(forecast_data[&#34;baseline&#34;])

    region_mask = (
        (forecast_data[&#34;lon&#34;].between(S.x_min, S.x_max))
        &amp; (forecast_data[&#34;lat&#34;].between(S.y_min, S.y_max))
        &amp; (forecast_data[&#34;measurement_end_utc&#34;] &gt; S.t_min)
        &amp; (forecast_data[&#34;measurement_end_utc&#34;] &lt;= S.t_max)
    )
    S_df = forecast_data.loc[region_mask]
    if S_df.empty:
        return 0, 0

    return S_df[&#34;baseline&#34;].sum() / 1e6, S_df[&#34;simulated&#34;].sum() / 1e6


def infer_global_region(data: pd.DataFrame) -&gt; Type[Region]:
    x_min = data[&#34;lon&#34;].min()
    x_max = data[&#34;lon&#34;].max()
    y_min = data[&#34;lat&#34;].min()
    y_max = data[&#34;lat&#34;].max()
    t_min = data[&#34;measurement_start_utc&#34;].min()
    t_max = data[&#34;measurement_end_utc&#34;].max()

    return Region(x_min, x_max, y_min, y_max, t_min, t_max)


def make_grid(global_region: Type[Region], N: int) -&gt; tuple:
    &#34;&#34;&#34;Function to create grid arrays to iterate over in the main loop. Divides
    the global region `global_region` into an N x N grid. Looping over the main
    grid is O(N^4 * W).
    Args:
        global_region: The whole domain of which the scan is performed over.
        N: Number of partitions per spatial axis.
    Returns:
        x: np.array of equally spaced values on the x axis of global_domain
        y: np.array of equally spaced values on the y axis of global_domain
        t: np.array of equally spaced values on the t axis of global_domain
    &#34;&#34;&#34;

    x = np.linspace(global_region.x_min, global_region.x_max, N + 1)
    y = np.linspace(global_region.y_min, global_region.y_max, N + 1)

    t = pd.date_range(start=global_region.t_min, end=global_region.t_max, freq=&#34;H&#34;)

    return x, y, t


def plot_global_region(
    forecast_data: pd.DataFrame,
    time_slice: datetime = None,
    overlay_grid: bool = True,
    grid_partition: int = 1,
    plot_type=&#34;count&#34;,
    add_legend: bool = True,
) -&gt; None:

    &#34;&#34;&#34;Functionality to plot the computational grid on a region of interest.
    To be mainly used as a visualisation tool for choosing the grid_partition
    value.
    Args:
        forecast_data: Resulting df from `count_baseline()`
        time_slice: Date time representing time slice to plot
        overlay_grid: Overlay computational grid or not.
        grid_parition: Number of divisions per spatial axis
        plot_type: counts, baselines or cb_ratio
    &#34;&#34;&#34;

    # Set defaults accordingly
    time_slice = (
        forecast_data[&#34;measurement_end_utc&#34;].iloc[0]
        if time_slice is None
        else time_slice
    )
    legend = &#34;brief&#34; if add_legend else False

    global_region = infer_global_region(forecast_data)
    x_ticks, y_ticks, _ = make_grid(global_region, grid_partition)
    forecast_data[&#34;cb_ratio&#34;] = forecast_data[&#34;count&#34;] / forecast_data[&#34;baseline&#34;]
    forecast_data.loc[~np.isfinite(forecast_data[&#34;cb_ratio&#34;]), &#34;cb_ratio&#34;] = np.nan
    forecast_data = forecast_data[forecast_data[&#34;measurement_end_utc&#34;] == time_slice]

    sbn.scatterplot(
        data=forecast_data,
        x=&#34;lon&#34;,
        y=&#34;lat&#34;,
        size=plot_type,
        legend=legend,
        hue=plot_type,
    )

    if overlay_grid:
        for _, x in enumerate(x_ticks[1:-1]):
            plt.axvline(x=x, alpha=0.4, c=&#34;k&#34;)
        for _, y in enumerate(y_ticks[1:-1]):
            plt.axhline(y=y, alpha=0.4, c=&#34;k&#34;)

    plt.title(&#34;Plot Type: {}, {}&#34;.format(plot_type, time_slice))
    plt.xlim([global_region.x_min, global_region.x_max])
    plt.ylim([global_region.y_min, global_region.y_max])

    return None


def make_region_from_res(
    res_df: pd.DataFrame, whole_prediction_period: bool = True, rank: int = 0
) -&gt; Type[Region]:
    &#34;&#34;&#34;The output of the main spatial scan loop is a dataframe named `res_df`.
    This function enables us to create a `Region` object from that resulting
    dataframe. The default is set to `rank=1`, meaning that the function will
    default to create a space-time region corresponding to the highest scoring
    likelihood ratio from the scan.

    Args:
        res_df: Resulting dataframe from the spatial scan
        whole_prediction_period: (Boolean) res_df will contain data spanning the
                                 the whole prediction period t= 0, 1, ... W. If
                                 set to true, the resulting region will span over
                                 all of these time steps. Otherwise, it will just
                                 return the highest scoring space-time region.
        rank: Determines which space-time region to create according to their
              likelihood ratio scores as determined by the loop.
    Returns:
        Space-Time region spanning the spatial region of interest. Time period
        either spans the whole prediction period, or just the highest scoring
        slice as explained above.
    &#34;&#34;&#34;

    x_min = res_df.iloc[rank].x_min
    x_max = res_df.iloc[rank].x_max
    y_min = res_df.iloc[rank].y_min
    y_max = res_df.iloc[rank].y_max
    if whole_prediction_period:
        t_min = res_df[&#34;t_min&#34;].min()
        t_max = res_df[&#34;t_max&#34;].max()
    else:
        t_min = res_df.iloc[rank].t_min
        t_max = res_df.iloc[rank].t_max
    return Region(x_min, x_max, y_min, y_max, t_min, t_max)


# Plot the time series of all detectors within a region of interest
def plot_region_time_series(
    region: Type[Region],
    forecast_df: pd.DataFrame,
    plot_type: str = &#34;count&#34;,
    add_legend: bool = False,
) -&gt; None:
    &#34;&#34;&#34;Plots all the time series associated with a space-time region. To be used
    in conjunction with `make_region_from_res` as follows:
        1. Find Highest scoring regions from the main scan loop
        2. Convert ones of interest (high-rank) to regions using
           `make_region_from_res`
        3. Plot the individual time series within that region using this function.
    Args:
        region: Space-Time Region of interest
        forecast_df: dataframe containing all prediction data from timeseries module.
    &#34;&#34;&#34;

    legend = &#34;brief&#34; if add_legend else False

    # Check for columns existence.
    assert set([&#34;lon&#34;, &#34;lat&#34;, &#34;measurement_end_utc&#34;, plot_type]) &lt;= set(
        forecast_df.columns
    )

    region_mask = (
        (forecast_df[&#34;lon&#34;].between(region.x_min, region.x_max))
        &amp; (forecast_df[&#34;lat&#34;].between(region.y_min, region.y_max))
        &amp; (forecast_df[&#34;measurement_end_utc&#34;] &gt; region.t_min)
        &amp; (forecast_df[&#34;measurement_end_utc&#34;] &lt;= region.t_max)
    )
    df = forecast_df.loc[region_mask]

    fig, ax = plt.subplots(figsize=(15, 6))
    sbn.lineplot(
        data=df,
        x=&#34;measurement_end_utc&#34;,
        y=plot_type,
        hue=&#34;detector_id&#34;,
        ax=ax,
        legend=legend,
    )
    fig.suptitle(&#34;{}s between {} and {}&#34;.format(plot_type, region.t_min, region.t_max))
    return None


def plot_region_by_rank(
    rank: int,
    res_df: pd.DataFrame,
    forecast_df: pd.DataFrame,
    plot_type=&#34;count&#34;,
    add_legend: bool = False,
) -&gt; None:

    &#34;&#34;&#34;Functionality to plot the &#39;rank&#39;ed region form the results dataframe
    superposed with the global grid.
    Args:
        rank: Rank of region within res_df dataframe. Best is 0.
        res_df: Resulting datafram from `EBP()`
        forecast_df: Resulting dataframe from `count_baseline()`
        plot_type: Size of dots represent actual counts, baseline or c/b ratio
    &#34;&#34;&#34;

    legend = &#34;brief&#34; if add_legend else False

    # Infer grid partition from the resulting dataframe
    grid_partition = len(res_df[&#34;x_min&#34;].unique())

    # Get grid partition here
    x_min = res_df[&#34;x_min&#34;].iloc[rank]
    x_max = res_df[&#34;x_max&#34;].iloc[rank]
    y_min = res_df[&#34;y_min&#34;].iloc[rank]
    y_max = res_df[&#34;y_max&#34;].iloc[rank]
    t_min = res_df[&#34;t_min&#34;].iloc[rank]
    t_max = res_df[&#34;t_max&#34;].iloc[rank]

    plot_global_region(
        forecast_df,
        res_df[&#34;t_max&#34;].iloc[rank],
        grid_partition=grid_partition,
        plot_type=plot_type,
        add_legend=legend,
    )
    plt.hlines(y_min, x_min, x_max)
    plt.hlines(y_max, x_min, x_max)
    plt.vlines(x_min, y_min, y_max)
    plt.vlines(x_max, y_min, y_max)
    plt.title(&#34;{}s between {} and {}. Rank: {}&#34;.format(plot_type, t_min, t_max, rank))

    plt.show()


def cleanse_forecast_data(forecast_df: pd.DataFrame) -&gt; pd.DataFrame:

    &#34;&#34;&#34;Utility function to ensure that the forecast_df from `count_baseline()`
    is in the correct format to move forward with processing. Removes NaNs, assigns
    zero to any negative baseline values, and converts dated into datetime format
    if required.
    Args:
        forecast_df: Data frame from `count_baseline()`
    Returns
        pd.DataFrame: Cleansed dataframe
    &#34;&#34;&#34;

    init_length = len(forecast_df[&#34;count&#34;])
    test_date = forecast_df[&#34;measurement_start_utc&#34;].iloc[0]

    # First check that dates are in the right format
    if isinstance(test_date, datetime):
        print(&#34;Dates in datetime format. Moving to next stage.\n&#34;)
    else:
        print(&#34;Dates are not in datetime format. Attempting to convert...&#34;)
        forecast_df = convert_dates(forecast_df)
        test_date = forecast_df[&#34;measurement_start_utc&#34;].iloc[0]
        print(
            &#34;Dates converted successfully: {}.\n&#34;.format(
                isinstance(test_date, datetime)
            )
        )

    # Remove Count NaN&#39;s
    count_nans = forecast_df[&#34;count&#34;].isnull().sum(axis=0)
    baseline_nans = forecast_df[&#34;baseline&#34;].isnull().sum(axis=0)
    print(
        &#34;{} NaN values found in &#39;count&#39; column. Dropping these from the dataframe.&#34;.format(
            count_nans
        )
    )
    print(
        &#34;{} NaN values found in &#39;baseline&#39; column. Dropping these from the dataframe.\n&#34;.format(
            baseline_nans
        )
    )
    forecast_df.dropna(inplace=True)

    # Make Baseline Values Non-Negative
    negative = len(forecast_df[forecast_df[&#34;baseline&#34;] &lt; 0][&#34;baseline&#34;])
    if negative &gt; 0:
        print(
            &#34;{} negative baseline values found. Setting these to zero.\n&#34;.format(
                negative
            )
        )
        forecast_df[&#34;baseline&#34;] = forecast_df[&#34;baseline&#34;].apply(
            lambda x: np.max([0, x])
        )
    else:
        print(&#34;All baseline predictions &gt;= 0.\n&#34;)

    final_length = len(forecast_df[&#34;count&#34;])
    print(
        &#34;Data cleansing complete. {} rows removed from dataframe.&#34;.format(
            init_length - final_length
        )
    )

    copy_df = forecast_df
    return copy_df</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="SpatialScan.region.aggregate_event_data"><code class="name flex">
<span>def <span class="ident">aggregate_event_data</span></span>(<span>forecast_data: pandas.core.frame.DataFrame, x_ticks: numpy.ndarray, y_ticks: numpy.ndarray, t_ticks: numpy.ndarray) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Functionality to aggregate data in forecast_data (each row represents
an event) to a data frame consisting N^2 * W rows (each row containing the
aggregated count in the grid cell it represents).
Clearly needs to be called after the grid is made.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>forecast_data</code></strong></dt>
<dd>Data from <code>count_baseline()</code></dd>
<dt><strong><code>x_ticks</code></strong></dt>
<dd>x axis grid</dd>
<dt><strong><code>y_ticks</code></strong></dt>
<dd>y axis grid</dd>
<dt><strong><code>t_ticks</code></strong></dt>
<dd>t_axis grid</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Aggregated Dataframe on Grid Cell Level.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def aggregate_event_data(
    forecast_data: pd.DataFrame,
    x_ticks: np.ndarray,
    y_ticks: np.ndarray,
    t_ticks: np.ndarray,
) -&gt; pd.DataFrame:
    &#34;&#34;&#34;Functionality to aggregate data in forecast_data (each row represents
    an event) to a data frame consisting N^2 * W rows (each row containing the
    aggregated count in the grid cell it represents).
    Clearly needs to be called after the grid is made.
    Args:
        forecast_data: Data from `count_baseline()`
        x_ticks: x axis grid
        y_ticks: y axis grid
        t_ticks: t_axis grid
    Returns:
        Aggregated Dataframe on Grid Cell Level.
    &#34;&#34;&#34;

    agg_dict = {}
    num_cells = 0
    for i in range(len(x_ticks) - 1):
        for j in range(len(y_ticks) - 1):
            for s in range(len(t_ticks) - 1):
                x_min = x_ticks[i]
                x_max = x_ticks[i + 1]
                y_min = y_ticks[j]
                y_max = y_ticks[j + 1]
                t_min = t_ticks[s]
                t_max = t_ticks[s + 1]

                sub_df = forecast_data[
                    (forecast_data[&#34;lon&#34;].between(x_min, x_max))
                    &amp; (forecast_data[&#34;lat&#34;].between(y_min, y_max))
                    &amp; (forecast_data[&#34;measurement_start_utc&#34;] == t_min)
                    &amp; (forecast_data[&#34;measurement_end_utc&#34;] == t_max)
                ]

                b_count = sub_df[&#34;baseline&#34;].sum()
                b_upper_count = sub_df[&#34;baseline_upper&#34;].sum()
                b_lower_count = sub_df[&#34;baseline_lower&#34;].sum()
                c_count = sub_df[&#34;count&#34;].sum()

                agg_dict[num_cells] = {
                    &#34;x_min&#34;: x_min,
                    &#34;x_max&#34;: x_max,
                    &#34;y_min&#34;: y_min,
                    &#34;y_max&#34;: y_max,
                    &#34;t_min&#34;: t_min,
                    &#34;t_max&#34;: t_max,
                    &#34;baseline_agg&#34;: b_count,
                    &#34;baseline_upper_agg&#34;: b_upper_count,
                    &#34;baseline_lower_agg&#34;: b_lower_count,
                    &#34;count_agg&#34;: c_count,
                }
                num_cells += 1

    return pd.DataFrame.from_dict(agg_dict, &#34;index&#34;)</code></pre>
</details>
</dd>
<dt id="SpatialScan.region.cleanse_forecast_data"><code class="name flex">
<span>def <span class="ident">cleanse_forecast_data</span></span>(<span>forecast_df: pandas.core.frame.DataFrame) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Utility function to ensure that the forecast_df from <code>count_baseline()</code>
is in the correct format to move forward with processing. Removes NaNs, assigns
zero to any negative baseline values, and converts dated into datetime format
if required.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>forecast_df</code></strong></dt>
<dd>Data frame from <code>count_baseline()</code></dd>
</dl>
<p>Returns
pd.DataFrame: Cleansed dataframe</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cleanse_forecast_data(forecast_df: pd.DataFrame) -&gt; pd.DataFrame:

    &#34;&#34;&#34;Utility function to ensure that the forecast_df from `count_baseline()`
    is in the correct format to move forward with processing. Removes NaNs, assigns
    zero to any negative baseline values, and converts dated into datetime format
    if required.
    Args:
        forecast_df: Data frame from `count_baseline()`
    Returns
        pd.DataFrame: Cleansed dataframe
    &#34;&#34;&#34;

    init_length = len(forecast_df[&#34;count&#34;])
    test_date = forecast_df[&#34;measurement_start_utc&#34;].iloc[0]

    # First check that dates are in the right format
    if isinstance(test_date, datetime):
        print(&#34;Dates in datetime format. Moving to next stage.\n&#34;)
    else:
        print(&#34;Dates are not in datetime format. Attempting to convert...&#34;)
        forecast_df = convert_dates(forecast_df)
        test_date = forecast_df[&#34;measurement_start_utc&#34;].iloc[0]
        print(
            &#34;Dates converted successfully: {}.\n&#34;.format(
                isinstance(test_date, datetime)
            )
        )

    # Remove Count NaN&#39;s
    count_nans = forecast_df[&#34;count&#34;].isnull().sum(axis=0)
    baseline_nans = forecast_df[&#34;baseline&#34;].isnull().sum(axis=0)
    print(
        &#34;{} NaN values found in &#39;count&#39; column. Dropping these from the dataframe.&#34;.format(
            count_nans
        )
    )
    print(
        &#34;{} NaN values found in &#39;baseline&#39; column. Dropping these from the dataframe.\n&#34;.format(
            baseline_nans
        )
    )
    forecast_df.dropna(inplace=True)

    # Make Baseline Values Non-Negative
    negative = len(forecast_df[forecast_df[&#34;baseline&#34;] &lt; 0][&#34;baseline&#34;])
    if negative &gt; 0:
        print(
            &#34;{} negative baseline values found. Setting these to zero.\n&#34;.format(
                negative
            )
        )
        forecast_df[&#34;baseline&#34;] = forecast_df[&#34;baseline&#34;].apply(
            lambda x: np.max([0, x])
        )
    else:
        print(&#34;All baseline predictions &gt;= 0.\n&#34;)

    final_length = len(forecast_df[&#34;count&#34;])
    print(
        &#34;Data cleansing complete. {} rows removed from dataframe.&#34;.format(
            init_length - final_length
        )
    )

    copy_df = forecast_df
    return copy_df</code></pre>
</details>
</dd>
<dt id="SpatialScan.region.convert_dates"><code class="name flex">
<span>def <span class="ident">convert_dates</span></span>(<span>df: pandas.core.frame.DataFrame, date_start_label='measurement_start_utc', date_end_label='measurement_end_utc') ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Utility functionality to convert dates in a dataframe from string to
datetime. Useful when reading in df from csv.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>df</code></strong></dt>
<dd>Any datafram with date columns</dd>
<dt><strong><code>date_start_label</code></strong></dt>
<dd>Label of the column in df corresponding to the start
date period.</dd>
<dt><strong><code>date_end_label</code></strong></dt>
<dd>Label of the column in df corresponding to the end
date period.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Dataframe with converted date columns</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def convert_dates(
    df: pd.DataFrame,
    date_start_label=&#34;measurement_start_utc&#34;,
    date_end_label=&#34;measurement_end_utc&#34;,
) -&gt; pd.DataFrame:

    &#34;&#34;&#34; Utility functionality to convert dates in a dataframe from string to
    datetime. Useful when reading in df from csv.
    Args:
        df: Any datafram with date columns
        date_start_label: Label of the column in df corresponding to the start
                          date period.
        date_end_label: Label of the column in df corresponding to the end
                          date period.
    Returns:
        Dataframe with converted date columns
    &#34;&#34;&#34;

    # Check columns are in here.
    assert set([date_start_label, date_end_label]) &lt;= set(df.columns)

    copy_df = df
    copy_df[date_start_label] = pd.to_datetime(df[date_start_label])
    copy_df[date_end_label] = pd.to_datetime(df[date_end_label])
    return copy_df</code></pre>
</details>
</dd>
<dt id="SpatialScan.region.event_count"><code class="name flex">
<span>def <span class="ident">event_count</span></span>(<span>S: Type[<a title="SpatialScan.region.Region" href="#SpatialScan.region.Region">Region</a>], agg_data: pandas.core.frame.DataFrame) ‑> dict</span>
</code></dt>
<dd>
<div class="desc"><p>Function to calculate both the expected (B) and actual (C) count
(vehicles) within a given space-time region S from the grid-cell-level-aggregated.
Used in the likelihood ratio statistic.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>S</code></strong></dt>
<dd>Space-Time Region to count events in</dd>
<dt><strong><code>agg_data</code></strong></dt>
<dd>Event counts aggregated at grid level. eg. from <code><a title="SpatialScan.region.aggregate_event_data" href="#SpatialScan.region.aggregate_event_data">aggregate_event_data()</a></code></dd>
</dl>
<p>Returns: (Tuple of floats) both types of event counts within region S.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def event_count(S: Type[Region], agg_data: pd.DataFrame) -&gt; dict:

    &#34;&#34;&#34;Function to calculate both the expected (B) and actual (C) count
    (vehicles) within a given space-time region S from the grid-cell-level-aggregated.
    Used in the likelihood ratio statistic.
    Args:
        S: Space-Time Region to count events in
        agg_data: Event counts aggregated at grid level. eg. from `aggregate_event_data()`
    Returns: (Tuple of floats) both types of event counts within region S.
    &#34;&#34;&#34;

    # Check for columns existence.
    assert set(
        [
            &#34;x_min&#34;,
            &#34;x_max&#34;,
            &#34;y_min&#34;,
            &#34;y_max&#34;,
            &#34;t_min&#34;,
            &#34;t_max&#34;,
            &#34;count_agg&#34;,
            &#34;baseline_agg&#34;,
        ]
    ) &lt;= set(agg_data.columns)

    region_mask = (
        (agg_data[&#34;x_min&#34;] &gt;= S.x_min)
        &amp; (agg_data[&#34;x_max&#34;] &lt;= S.x_max)
        &amp; (agg_data[&#34;y_min&#34;] &gt;= S.y_min)
        &amp; (agg_data[&#34;y_max&#34;] &lt;= S.y_max)
        &amp; (agg_data[&#34;t_min&#34;] &gt;= S.t_min)
        &amp; (agg_data[&#34;t_max&#34;] &lt;= S.t_max)
    )

    S_df = agg_data.loc[region_mask]
    if S_df.empty:
        return {&#39;baseline_agg&#39;: 0, &#39;count_agg&#39;: 0, &#39;baseline_upper_agg&#39;: 0, &#39;baseline_lower_agg&#39;: 0}
    return {&#39;baseline&#39;: S_df[&#39;baseline_agg&#39;].sum() / 1e6,
            &#39;count&#39;: S_df[&#39;count_agg&#39;].sum() / 1e6,
            &#39;baseline_upper&#39;: S_df[&#39;baseline_upper_agg&#39;].sum() / 1e6,
            &#39;baseline_lower&#39;: S_df[&#39;baseline_lower_agg&#39;].sum() / 1e6
    }</code></pre>
</details>
</dd>
<dt id="SpatialScan.region.infer_global_region"><code class="name flex">
<span>def <span class="ident">infer_global_region</span></span>(<span>data: pandas.core.frame.DataFrame) ‑> Type[<a title="SpatialScan.region.Region" href="#SpatialScan.region.Region">Region</a>]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def infer_global_region(data: pd.DataFrame) -&gt; Type[Region]:
    x_min = data[&#34;lon&#34;].min()
    x_max = data[&#34;lon&#34;].max()
    y_min = data[&#34;lat&#34;].min()
    y_max = data[&#34;lat&#34;].max()
    t_min = data[&#34;measurement_start_utc&#34;].min()
    t_max = data[&#34;measurement_end_utc&#34;].max()

    return Region(x_min, x_max, y_min, y_max, t_min, t_max)</code></pre>
</details>
</dd>
<dt id="SpatialScan.region.make_grid"><code class="name flex">
<span>def <span class="ident">make_grid</span></span>(<span>global_region: Type[<a title="SpatialScan.region.Region" href="#SpatialScan.region.Region">Region</a>], N: int) ‑> tuple</span>
</code></dt>
<dd>
<div class="desc"><p>Function to create grid arrays to iterate over in the main loop. Divides
the global region <code>global_region</code> into an N x N grid. Looping over the main
grid is O(N^4 * W).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>global_region</code></strong></dt>
<dd>The whole domain of which the scan is performed over.</dd>
<dt><strong><code>N</code></strong></dt>
<dd>Number of partitions per spatial axis.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>x</code></dt>
<dd>np.array of equally spaced values on the x axis of global_domain</dd>
<dt><code>y</code></dt>
<dd>np.array of equally spaced values on the y axis of global_domain</dd>
<dt><code>t</code></dt>
<dd>np.array of equally spaced values on the t axis of global_domain</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_grid(global_region: Type[Region], N: int) -&gt; tuple:
    &#34;&#34;&#34;Function to create grid arrays to iterate over in the main loop. Divides
    the global region `global_region` into an N x N grid. Looping over the main
    grid is O(N^4 * W).
    Args:
        global_region: The whole domain of which the scan is performed over.
        N: Number of partitions per spatial axis.
    Returns:
        x: np.array of equally spaced values on the x axis of global_domain
        y: np.array of equally spaced values on the y axis of global_domain
        t: np.array of equally spaced values on the t axis of global_domain
    &#34;&#34;&#34;

    x = np.linspace(global_region.x_min, global_region.x_max, N + 1)
    y = np.linspace(global_region.y_min, global_region.y_max, N + 1)

    t = pd.date_range(start=global_region.t_min, end=global_region.t_max, freq=&#34;H&#34;)

    return x, y, t</code></pre>
</details>
</dd>
<dt id="SpatialScan.region.make_region_from_res"><code class="name flex">
<span>def <span class="ident">make_region_from_res</span></span>(<span>res_df: pandas.core.frame.DataFrame, whole_prediction_period: bool = True, rank: int = 0) ‑> Type[<a title="SpatialScan.region.Region" href="#SpatialScan.region.Region">Region</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>The output of the main spatial scan loop is a dataframe named <code>res_df</code>.
This function enables us to create a <code><a title="SpatialScan.region.Region" href="#SpatialScan.region.Region">Region</a></code> object from that resulting
dataframe. The default is set to <code>rank=1</code>, meaning that the function will
default to create a space-time region corresponding to the highest scoring
likelihood ratio from the scan.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>res_df</code></strong></dt>
<dd>Resulting dataframe from the spatial scan</dd>
<dt><strong><code>whole_prediction_period</code></strong></dt>
<dd>(Boolean) res_df will contain data spanning the
the whole prediction period t= 0, 1, &hellip; W. If
set to true, the resulting region will span over
all of these time steps. Otherwise, it will just
return the highest scoring space-time region.</dd>
<dt><strong><code>rank</code></strong></dt>
<dd>Determines which space-time region to create according to their
likelihood ratio scores as determined by the loop.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Space-Time region spanning the spatial region of interest. Time period
either spans the whole prediction period, or just the highest scoring
slice as explained above.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_region_from_res(
    res_df: pd.DataFrame, whole_prediction_period: bool = True, rank: int = 0
) -&gt; Type[Region]:
    &#34;&#34;&#34;The output of the main spatial scan loop is a dataframe named `res_df`.
    This function enables us to create a `Region` object from that resulting
    dataframe. The default is set to `rank=1`, meaning that the function will
    default to create a space-time region corresponding to the highest scoring
    likelihood ratio from the scan.

    Args:
        res_df: Resulting dataframe from the spatial scan
        whole_prediction_period: (Boolean) res_df will contain data spanning the
                                 the whole prediction period t= 0, 1, ... W. If
                                 set to true, the resulting region will span over
                                 all of these time steps. Otherwise, it will just
                                 return the highest scoring space-time region.
        rank: Determines which space-time region to create according to their
              likelihood ratio scores as determined by the loop.
    Returns:
        Space-Time region spanning the spatial region of interest. Time period
        either spans the whole prediction period, or just the highest scoring
        slice as explained above.
    &#34;&#34;&#34;

    x_min = res_df.iloc[rank].x_min
    x_max = res_df.iloc[rank].x_max
    y_min = res_df.iloc[rank].y_min
    y_max = res_df.iloc[rank].y_max
    if whole_prediction_period:
        t_min = res_df[&#34;t_min&#34;].min()
        t_max = res_df[&#34;t_max&#34;].max()
    else:
        t_min = res_df.iloc[rank].t_min
        t_max = res_df.iloc[rank].t_max
    return Region(x_min, x_max, y_min, y_max, t_min, t_max)</code></pre>
</details>
</dd>
<dt id="SpatialScan.region.plot_global_region"><code class="name flex">
<span>def <span class="ident">plot_global_region</span></span>(<span>forecast_data: pandas.core.frame.DataFrame, time_slice: datetime.datetime = None, overlay_grid: bool = True, grid_partition: int = 1, plot_type='count', add_legend: bool = True) ‑> NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Functionality to plot the computational grid on a region of interest.
To be mainly used as a visualisation tool for choosing the grid_partition
value.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>forecast_data</code></strong></dt>
<dd>Resulting df from <code>count_baseline()</code></dd>
<dt><strong><code>time_slice</code></strong></dt>
<dd>Date time representing time slice to plot</dd>
<dt><strong><code>overlay_grid</code></strong></dt>
<dd>Overlay computational grid or not.</dd>
<dt><strong><code>grid_parition</code></strong></dt>
<dd>Number of divisions per spatial axis</dd>
<dt><strong><code>plot_type</code></strong></dt>
<dd>counts, baselines or cb_ratio</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_global_region(
    forecast_data: pd.DataFrame,
    time_slice: datetime = None,
    overlay_grid: bool = True,
    grid_partition: int = 1,
    plot_type=&#34;count&#34;,
    add_legend: bool = True,
) -&gt; None:

    &#34;&#34;&#34;Functionality to plot the computational grid on a region of interest.
    To be mainly used as a visualisation tool for choosing the grid_partition
    value.
    Args:
        forecast_data: Resulting df from `count_baseline()`
        time_slice: Date time representing time slice to plot
        overlay_grid: Overlay computational grid or not.
        grid_parition: Number of divisions per spatial axis
        plot_type: counts, baselines or cb_ratio
    &#34;&#34;&#34;

    # Set defaults accordingly
    time_slice = (
        forecast_data[&#34;measurement_end_utc&#34;].iloc[0]
        if time_slice is None
        else time_slice
    )
    legend = &#34;brief&#34; if add_legend else False

    global_region = infer_global_region(forecast_data)
    x_ticks, y_ticks, _ = make_grid(global_region, grid_partition)
    forecast_data[&#34;cb_ratio&#34;] = forecast_data[&#34;count&#34;] / forecast_data[&#34;baseline&#34;]
    forecast_data.loc[~np.isfinite(forecast_data[&#34;cb_ratio&#34;]), &#34;cb_ratio&#34;] = np.nan
    forecast_data = forecast_data[forecast_data[&#34;measurement_end_utc&#34;] == time_slice]

    sbn.scatterplot(
        data=forecast_data,
        x=&#34;lon&#34;,
        y=&#34;lat&#34;,
        size=plot_type,
        legend=legend,
        hue=plot_type,
    )

    if overlay_grid:
        for _, x in enumerate(x_ticks[1:-1]):
            plt.axvline(x=x, alpha=0.4, c=&#34;k&#34;)
        for _, y in enumerate(y_ticks[1:-1]):
            plt.axhline(y=y, alpha=0.4, c=&#34;k&#34;)

    plt.title(&#34;Plot Type: {}, {}&#34;.format(plot_type, time_slice))
    plt.xlim([global_region.x_min, global_region.x_max])
    plt.ylim([global_region.y_min, global_region.y_max])

    return None</code></pre>
</details>
</dd>
<dt id="SpatialScan.region.plot_region_by_rank"><code class="name flex">
<span>def <span class="ident">plot_region_by_rank</span></span>(<span>rank: int, res_df: pandas.core.frame.DataFrame, forecast_df: pandas.core.frame.DataFrame, plot_type='count', add_legend: bool = False) ‑> NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Functionality to plot the 'rank'ed region form the results dataframe
superposed with the global grid.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>rank</code></strong></dt>
<dd>Rank of region within res_df dataframe. Best is 0.</dd>
<dt><strong><code>res_df</code></strong></dt>
<dd>Resulting datafram from <code>EBP()</code></dd>
<dt><strong><code>forecast_df</code></strong></dt>
<dd>Resulting dataframe from <code>count_baseline()</code></dd>
<dt><strong><code>plot_type</code></strong></dt>
<dd>Size of dots represent actual counts, baseline or c/b ratio</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_region_by_rank(
    rank: int,
    res_df: pd.DataFrame,
    forecast_df: pd.DataFrame,
    plot_type=&#34;count&#34;,
    add_legend: bool = False,
) -&gt; None:

    &#34;&#34;&#34;Functionality to plot the &#39;rank&#39;ed region form the results dataframe
    superposed with the global grid.
    Args:
        rank: Rank of region within res_df dataframe. Best is 0.
        res_df: Resulting datafram from `EBP()`
        forecast_df: Resulting dataframe from `count_baseline()`
        plot_type: Size of dots represent actual counts, baseline or c/b ratio
    &#34;&#34;&#34;

    legend = &#34;brief&#34; if add_legend else False

    # Infer grid partition from the resulting dataframe
    grid_partition = len(res_df[&#34;x_min&#34;].unique())

    # Get grid partition here
    x_min = res_df[&#34;x_min&#34;].iloc[rank]
    x_max = res_df[&#34;x_max&#34;].iloc[rank]
    y_min = res_df[&#34;y_min&#34;].iloc[rank]
    y_max = res_df[&#34;y_max&#34;].iloc[rank]
    t_min = res_df[&#34;t_min&#34;].iloc[rank]
    t_max = res_df[&#34;t_max&#34;].iloc[rank]

    plot_global_region(
        forecast_df,
        res_df[&#34;t_max&#34;].iloc[rank],
        grid_partition=grid_partition,
        plot_type=plot_type,
        add_legend=legend,
    )
    plt.hlines(y_min, x_min, x_max)
    plt.hlines(y_max, x_min, x_max)
    plt.vlines(x_min, y_min, y_max)
    plt.vlines(x_max, y_min, y_max)
    plt.title(&#34;{}s between {} and {}. Rank: {}&#34;.format(plot_type, t_min, t_max, rank))

    plt.show()</code></pre>
</details>
</dd>
<dt id="SpatialScan.region.plot_region_time_series"><code class="name flex">
<span>def <span class="ident">plot_region_time_series</span></span>(<span>region: Type[<a title="SpatialScan.region.Region" href="#SpatialScan.region.Region">Region</a>], forecast_df: pandas.core.frame.DataFrame, plot_type: str = 'count', add_legend: bool = False) ‑> NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Plots all the time series associated with a space-time region. To be used
in conjunction with <code><a title="SpatialScan.region.make_region_from_res" href="#SpatialScan.region.make_region_from_res">make_region_from_res()</a></code> as follows:
1. Find Highest scoring regions from the main scan loop
2. Convert ones of interest (high-rank) to regions using
<code><a title="SpatialScan.region.make_region_from_res" href="#SpatialScan.region.make_region_from_res">make_region_from_res()</a></code>
3. Plot the individual time series within that region using this function.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>region</code></strong></dt>
<dd>Space-Time Region of interest</dd>
<dt><strong><code>forecast_df</code></strong></dt>
<dd>dataframe containing all prediction data from timeseries module.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_region_time_series(
    region: Type[Region],
    forecast_df: pd.DataFrame,
    plot_type: str = &#34;count&#34;,
    add_legend: bool = False,
) -&gt; None:
    &#34;&#34;&#34;Plots all the time series associated with a space-time region. To be used
    in conjunction with `make_region_from_res` as follows:
        1. Find Highest scoring regions from the main scan loop
        2. Convert ones of interest (high-rank) to regions using
           `make_region_from_res`
        3. Plot the individual time series within that region using this function.
    Args:
        region: Space-Time Region of interest
        forecast_df: dataframe containing all prediction data from timeseries module.
    &#34;&#34;&#34;

    legend = &#34;brief&#34; if add_legend else False

    # Check for columns existence.
    assert set([&#34;lon&#34;, &#34;lat&#34;, &#34;measurement_end_utc&#34;, plot_type]) &lt;= set(
        forecast_df.columns
    )

    region_mask = (
        (forecast_df[&#34;lon&#34;].between(region.x_min, region.x_max))
        &amp; (forecast_df[&#34;lat&#34;].between(region.y_min, region.y_max))
        &amp; (forecast_df[&#34;measurement_end_utc&#34;] &gt; region.t_min)
        &amp; (forecast_df[&#34;measurement_end_utc&#34;] &lt;= region.t_max)
    )
    df = forecast_df.loc[region_mask]

    fig, ax = plt.subplots(figsize=(15, 6))
    sbn.lineplot(
        data=df,
        x=&#34;measurement_end_utc&#34;,
        y=plot_type,
        hue=&#34;detector_id&#34;,
        ax=ax,
        legend=legend,
    )
    fig.suptitle(&#34;{}s between {} and {}&#34;.format(plot_type, region.t_min, region.t_max))
    return None</code></pre>
</details>
</dd>
<dt id="SpatialScan.region.simulate_event_count"><code class="name flex">
<span>def <span class="ident">simulate_event_count</span></span>(<span>S: Type[<a title="SpatialScan.region.Region" href="#SpatialScan.region.Region">Region</a>], forecast_data: pandas.core.frame.DataFrame) ‑> tuple</span>
</code></dt>
<dd>
<div class="desc"><p>Function to simulate the count (vehicles) within a given
space-time region S assuming a Poisson Distribution with mean given by the
baseline forecast. Used in randomisation testing.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>S</code></strong></dt>
<dd>Space-Time Region to count events in</dd>
<dt><strong><code>data</code></strong></dt>
<dd>Forecast data from <code>count_baseline()</code></dd>
</dl>
<p>Returns: (Tuple of floats) both types of event counts within region S.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def simulate_event_count(S: Type[Region], forecast_data: pd.DataFrame) -&gt; tuple:

    &#34;&#34;&#34;Function to simulate the count (vehicles) within a given
    space-time region S assuming a Poisson Distribution with mean given by the
    baseline forecast. Used in randomisation testing.
    Args:
        S: Space-Time Region to count events in
        data: Forecast data from `count_baseline()`
    Returns: (Tuple of floats) both types of event counts within region S.
    &#34;&#34;&#34;

    # Check for columns existence.
    assert set([&#34;lon&#34;, &#34;lat&#34;, &#34;measurement_end_utc&#34;, &#34;count&#34;, &#34;baseline&#34;]) &lt;= set(
        forecast_data.columns
    )

    forecast_data[&#34;simulated&#34;] = np.random.poisson(forecast_data[&#34;baseline&#34;])

    region_mask = (
        (forecast_data[&#34;lon&#34;].between(S.x_min, S.x_max))
        &amp; (forecast_data[&#34;lat&#34;].between(S.y_min, S.y_max))
        &amp; (forecast_data[&#34;measurement_end_utc&#34;] &gt; S.t_min)
        &amp; (forecast_data[&#34;measurement_end_utc&#34;] &lt;= S.t_max)
    )
    S_df = forecast_data.loc[region_mask]
    if S_df.empty:
        return 0, 0

    return S_df[&#34;baseline&#34;].sum() / 1e6, S_df[&#34;simulated&#34;].sum() / 1e6</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="SpatialScan.region.Region"><code class="flex name class">
<span>class <span class="ident">Region</span></span>
<span>(</span><span>x_min: float, x_max: float, y_min: float, y_max: float, t_min: datetime.datetime, t_max: datetime.datetime)</span>
</code></dt>
<dd>
<div class="desc"><p>Class to represent space-time region</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Region:
    &#34;&#34;&#34;Class to represent space-time region&#34;&#34;&#34;

    def __init__(
        self,
        x_min: float,
        x_max: float,
        y_min: float,
        y_max: float,
        t_min: datetime,
        t_max: datetime,
    ) -&gt; None:
        self.x_min = x_min
        self.x_max = x_max
        self.y_min = y_min
        self.y_max = y_max
        self.t_min = t_min
        self.t_max = t_max
        self.label = None

    def __str__(self):
        return &#34;({}, {}) x ({}, {}) x ({}, {})&#34;.format(
            self.x_min, self.x_max, self.y_min, self.y_max, self.t_min, self.t_max
        )

    def add_label(self, label):
        self.label = label

    def num_days(self):
        return (self.t_max - self.t_min).days

    def num_hours(self):
        return (self.t_max - self.t_min).days * 24</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="SpatialScan.region.Region.add_label"><code class="name flex">
<span>def <span class="ident">add_label</span></span>(<span>self, label)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_label(self, label):
    self.label = label</code></pre>
</details>
</dd>
<dt id="SpatialScan.region.Region.num_days"><code class="name flex">
<span>def <span class="ident">num_days</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def num_days(self):
    return (self.t_max - self.t_min).days</code></pre>
</details>
</dd>
<dt id="SpatialScan.region.Region.num_hours"><code class="name flex">
<span>def <span class="ident">num_hours</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def num_hours(self):
    return (self.t_max - self.t_min).days * 24</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="SpatialScan" href="index.html">SpatialScan</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="SpatialScan.region.aggregate_event_data" href="#SpatialScan.region.aggregate_event_data">aggregate_event_data</a></code></li>
<li><code><a title="SpatialScan.region.cleanse_forecast_data" href="#SpatialScan.region.cleanse_forecast_data">cleanse_forecast_data</a></code></li>
<li><code><a title="SpatialScan.region.convert_dates" href="#SpatialScan.region.convert_dates">convert_dates</a></code></li>
<li><code><a title="SpatialScan.region.event_count" href="#SpatialScan.region.event_count">event_count</a></code></li>
<li><code><a title="SpatialScan.region.infer_global_region" href="#SpatialScan.region.infer_global_region">infer_global_region</a></code></li>
<li><code><a title="SpatialScan.region.make_grid" href="#SpatialScan.region.make_grid">make_grid</a></code></li>
<li><code><a title="SpatialScan.region.make_region_from_res" href="#SpatialScan.region.make_region_from_res">make_region_from_res</a></code></li>
<li><code><a title="SpatialScan.region.plot_global_region" href="#SpatialScan.region.plot_global_region">plot_global_region</a></code></li>
<li><code><a title="SpatialScan.region.plot_region_by_rank" href="#SpatialScan.region.plot_region_by_rank">plot_region_by_rank</a></code></li>
<li><code><a title="SpatialScan.region.plot_region_time_series" href="#SpatialScan.region.plot_region_time_series">plot_region_time_series</a></code></li>
<li><code><a title="SpatialScan.region.simulate_event_count" href="#SpatialScan.region.simulate_event_count">simulate_event_count</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="SpatialScan.region.Region" href="#SpatialScan.region.Region">Region</a></code></h4>
<ul class="">
<li><code><a title="SpatialScan.region.Region.add_label" href="#SpatialScan.region.Region.add_label">add_label</a></code></li>
<li><code><a title="SpatialScan.region.Region.num_days" href="#SpatialScan.region.Region.num_days">num_days</a></code></li>
<li><code><a title="SpatialScan.region.Region.num_hours" href="#SpatialScan.region.Region.num_hours">num_hours</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.4</a>.</p>
</footer>
</body>
</html>